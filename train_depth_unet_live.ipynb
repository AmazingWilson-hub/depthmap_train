{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grayscale Depth Training (UNet) — Live Curves\n",
        "\n",
        "Train a single-channel UNet for depth regression with **live loss/metric plots**.\n",
        "\n",
        "**Features**\n",
        "- Config cell to tweak params\n",
        "- Mixed precision on CUDA\n",
        "- L1 + SiLog loss\n",
        "- Per-epoch RMSE / AbsRel on val\n",
        "- **Live charts** updated every epoch\n",
        "- Save `best.pt`, `last.pt`, `history.csv`, and `curves.png`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Config (EDIT) =====\n",
        "config = {\n",
        "    \"train_images\": \"data_v2/train/images\",\n",
        "    \"train_depths\": \"data_v2/train/depths\",\n",
        "    \"val_images\":   \"data_v2/val/images\",\n",
        "    \"val_depths\":   \"data_v2/val/depths\",\n",
        "    \"img_size\": 384,\n",
        "    \"max_depth\": 80.0,  # set to your dataset's ~P99\n",
        "    \"batch\": 16,\n",
        "    \"epochs\": 50,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"w_l1\": 1.0,\n",
        "    \"w_silog\": 0.1,\n",
        "    \"device\": \"cuda\",           # 'cuda' on 4080S, else 'cpu'\n",
        "    \"out_dir\": \"runs/dep_unet_v2\"\n",
        "}\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Imports & utils =====\n",
        "import os, math, time, random, csv\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.utils as vutils  # 若要偶爾寫入可視化用\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def valid_mask_from(gt: torch.Tensor):\n",
        "    return torch.isfinite(gt) & (gt > 0)\n",
        "\n",
        "def rmse(pred, gt, mask):\n",
        "    if mask.sum() == 0: return torch.tensor(float('nan'), device=pred.device)\n",
        "    return torch.sqrt(F.mse_loss(pred[mask], gt[mask]))\n",
        "\n",
        "def abs_rel(pred, gt, mask):\n",
        "    if mask.sum() == 0: return torch.tensor(float('nan'), device=pred.device)\n",
        "    return ((pred[mask] - gt[mask]).abs() / gt[mask].clamp_min(1e-6)).mean()\n",
        "\n",
        "def to_device(batch, device):\n",
        "    x,y,m = batch\n",
        "    return x.to(device, non_blocking=True), y.to(device, non_blocking=True), m.to(device, non_blocking=True)\n",
        "\n",
        "device = torch.device('cuda' if (config['device']=='cuda' and torch.cuda.is_available()) else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class ImageDepthNPY(Dataset):\n",
        "    def __init__(self, img_dir, dep_dir, img_size=384, max_depth=80.0, aug=False, allow_exts=None):\n",
        "        self.img_dir = Path(img_dir); self.dep_dir = Path(dep_dir)\n",
        "        self.img_size = int(img_size); self.max_depth = float(max_depth)\n",
        "        self.aug = bool(aug)\n",
        "        if allow_exts is None:\n",
        "            allow_exts = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "\n",
        "        imgs = [p for p in self.img_dir.iterdir() if p.is_file() and p.suffix.lower() in allow_exts]\n",
        "        imgs = sorted(imgs)\n",
        "\n",
        "        self.samples = []\n",
        "        for p in imgs:\n",
        "            npy = self.dep_dir / (p.stem + '.npy')\n",
        "            if npy.exists():\n",
        "                self.samples.append((p, npy))\n",
        "        self.samples = sorted(self.samples)\n",
        "\n",
        "        if not self.samples:\n",
        "            raise FileNotFoundError(f'No paired samples under {img_dir} & {dep_dir}')\n",
        "\n",
        "        # 僅保留「強度」相關的 normalize；幾何由我們自己同步處理\n",
        "        self.to_tensor = T.ToTensor()\n",
        "        self.norm = T.Normalize(mean=(0.5,), std=(0.5,))\n",
        "\n",
        "        # RandomResizedCrop 參數\n",
        "        self.scale_range = (0.7, 1.0)\n",
        "        self.ratio_range = (3/4, 4/3)\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.samples)\n",
        "\n",
        "    def _random_resized_crop_params(self, w, h):\n",
        "        # 使用 torchvision 官方的取參邏輯\n",
        "        i, j, h_out, w_out = T.RandomResizedCrop.get_params(\n",
        "            img=torch.empty(1, h, w),  # 只需尺寸\n",
        "            scale=self.scale_range,\n",
        "            ratio=self.ratio_range\n",
        "        )\n",
        "        return i, j, h_out, w_out\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_p, dep_p = self.samples[idx]\n",
        "\n",
        "        # --- load ---\n",
        "        pil = Image.open(img_p).convert('L')  # [H, W]\n",
        "        d_np = np.load(dep_p).astype(np.float32)  # [H, W]\n",
        "        d = torch.from_numpy(d_np).unsqueeze(0)   # [1, H, W]  (單通道深度)\n",
        "\n",
        "        # --- geometry (同步影像 & 深度) ---\n",
        "        if self.aug:\n",
        "            # 抽一次參數，套用到兩者\n",
        "            i, j, h_out, w_out = self._random_resized_crop_params(pil.width, pil.height)\n",
        "            pil = TF.resized_crop(pil, top=i, left=j, height=h_out, width=w_out, size=[self.img_size, self.img_size], antialias=True)\n",
        "            # 對深度做相同裁切與resize；避免混值，resize 用 nearest\n",
        "            d = d[:, i:i+h_out, j:j+w_out]\n",
        "            d = d.unsqueeze(0)  # [1,1,h,w]\n",
        "            d = F.interpolate(d, size=(self.img_size, self.img_size), mode='nearest').squeeze(0)  # [1,H,W]\n",
        "        else:\n",
        "            pil = TF.resize(pil, [self.img_size, self.img_size], antialias=True)\n",
        "            d = d.unsqueeze(0)\n",
        "            d = F.interpolate(d, size=(self.img_size, self.img_size), mode='nearest').squeeze(0)\n",
        "\n",
        "        # --- to tensor & normalize ---\n",
        "        x = self.to_tensor(pil)          # [1,H,W], 0~1\n",
        "        x = self.norm(x)                 # normalize\n",
        "\n",
        "        # --- mask & normalize depth ---\n",
        "        # 先做有效遮罩，再正規化；同時忽略超過上限的值（可選）\n",
        "        m = torch.isfinite(d) & (d > 0) & (d <= self.max_depth)\n",
        "        y = torch.zeros_like(d)\n",
        "        if m.any():\n",
        "            y[m] = (d[m] / self.max_depth).clamp(0, 1)\n",
        "\n",
        "        # --- horizontal flip (一致套用到三者) ---\n",
        "        if self.aug and random.random() < 0.5:\n",
        "            x = torch.flip(x, dims=[2])\n",
        "            y = torch.flip(y, dims=[2])\n",
        "            m = torch.flip(m, dims=[2])\n",
        "\n",
        "        return x, y, m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_c, out_c, norm=\"bn\"):\n",
        "        super().__init__()\n",
        "        Norm = nn.BatchNorm2d if norm==\"bn\" else lambda c: nn.GroupNorm(32, c)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
        "            Norm(out_c),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
        "            Norm(out_c),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_c, skip_c, out_c, norm=\"bn\"):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
        "        self.conv = DoubleConv(in_c + skip_c, out_c, norm=norm)\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNetSmall(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1, norm=\"bn\", final_act=\"sigmoid\"):\n",
        "        super().__init__()\n",
        "        ch = [64,128,256,512]\n",
        "        self.d1 = DoubleConv(in_ch,   ch[0], norm)\n",
        "        self.p1 = nn.MaxPool2d(2)\n",
        "        self.d2 = DoubleConv(ch[0],   ch[1], norm)\n",
        "        self.p2 = nn.MaxPool2d(2)\n",
        "        self.d3 = DoubleConv(ch[1],   ch[2], norm)\n",
        "        self.p3 = nn.MaxPool2d(2)\n",
        "        self.d4 = DoubleConv(ch[2],   ch[3], norm)\n",
        "\n",
        "        self.u3 = UpBlock(ch[3], ch[2], ch[2], norm)\n",
        "        self.u2 = UpBlock(ch[2], ch[1], ch[1], norm)\n",
        "        self.u1 = UpBlock(ch[1], ch[0], ch[0], norm)\n",
        "\n",
        "        self.head = nn.Conv2d(ch[0], out_ch, 1)\n",
        "        self.final_act = final_act\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.d1(x)\n",
        "        x2 = self.d2(self.p1(x1))\n",
        "        x3 = self.d3(self.p2(x2))\n",
        "        x4 = self.d4(self.p3(x3))\n",
        "\n",
        "        y  = self.u3(x4, x3)\n",
        "        y  = self.u2(y,  x2)\n",
        "        y  = self.u1(y,  x1)\n",
        "        y  = self.head(y)\n",
        "\n",
        "        if self.final_act == \"sigmoid\":\n",
        "            y = torch.sigmoid(y)\n",
        "        elif self.final_act == \"relu\":\n",
        "            y = torch.relu(y).clamp_(0,1)\n",
        "        # else: linear (no activation), 交給 loss 再 clamp\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DepthLoss(nn.Module):\n",
        "    def __init__(self, w_l1=1.0, w_silog=0.1, clamp01=True):\n",
        "        super().__init__()\n",
        "        self.w_l1 = float(w_l1)\n",
        "        self.w_silog = float(w_silog)\n",
        "        self.clamp01 = clamp01\n",
        "\n",
        "    def silog(self, pred, gt, mask, eps=1e-6, lam=0.85):\n",
        "        # 僅在有效像素上計算\n",
        "        p = pred[mask]\n",
        "        g = gt[mask]\n",
        "        # 數值穩定\n",
        "        d = (p.clamp_min(eps)).log() - (g.clamp_min(eps)).log()\n",
        "        return torch.mean(d * d) - lam * (torch.mean(d) ** 2)\n",
        "\n",
        "    def forward(self, pred, gt, mask):\n",
        "        if self.clamp01:\n",
        "            pred = pred.clamp(0, 1)\n",
        "\n",
        "        loss = pred.new_tensor(0.0)\n",
        "        if mask.any():\n",
        "            if self.w_l1 > 0:\n",
        "                loss = loss + self.w_l1 * F.l1_loss(pred[mask], gt[mask])\n",
        "            if self.w_silog > 0:\n",
        "                loss = loss + self.w_silog * self.silog(pred, gt, mask)\n",
        "        # 如果整個 batch 都沒有有效像素，就回 0（或回 nan 也行，看你要不要讓外層丟棄）\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Train with tqdm batch bar =====\n",
        "from tqdm import tqdm\n",
        "import platform\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Windows + Notebook 最穩：num_workers=0, pin_memory=False\n",
        "num_workers = 0\n",
        "pin_mem = False\n",
        "if platform.system() == \"Linux\" and device.type == \"cuda\":\n",
        "    # 你在 Linux server 可試著開高一點\n",
        "    num_workers = 4\n",
        "    pin_mem = True\n",
        "\n",
        "train_set = ImageDepthNPY(config['train_images'], config['train_depths'], config['img_size'], config['max_depth'], aug=True)\n",
        "val_set   = ImageDepthNPY(config['val_images'],   config['val_depths'],   config['img_size'], config['max_depth'], aug=False)\n",
        "\n",
        "print(\"train samples:\", len(train_set), \"val samples:\", len(val_set))\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size=config['batch'], shuffle=True,\n",
        "    num_workers=num_workers, pin_memory=pin_mem, drop_last=True\n",
        ")\n",
        "val_loader   = DataLoader(\n",
        "    val_set, batch_size=config['batch'], shuffle=False,\n",
        "    num_workers=num_workers, pin_memory=pin_mem\n",
        ")\n",
        "print(\"batches per epoch -> train:\", len(train_loader), \"val:\", len(val_loader))\n",
        "\n",
        "model = UNetSmall(in_ch=1).to(device)\n",
        "loss_fn = DepthLoss(config['w_l1'], config['w_silog'])\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "\n",
        "def lr_lambda(e):\n",
        "    warm=max(3,int(0.1*config['epochs']))\n",
        "    if e < warm: return (e+1)/warm\n",
        "    prog=(e-warm)/max(1, config['epochs']-warm)\n",
        "    return 0.5*(1+math.cos(math.pi*prog))\n",
        "sch = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
        "\n",
        "outdir = Path(config['out_dir']); outdir.mkdir(parents=True, exist_ok=True)\n",
        "run_name = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "tb_dir = outdir / f\"tb_{run_name}\"\n",
        "tb_dir.mkdir(parents=True, exist_ok=True)\n",
        "writer = SummaryWriter(log_dir=str(tb_dir))\n",
        "\n",
        "# 可選：把 config 也記下，之後查參數方便\n",
        "for k, v in config.items():\n",
        "    writer.add_text(\"config\", f\"{k}: {v}\", global_step=0)\n",
        "\n",
        "best_rmse=float('inf')\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
        "\n",
        "hist = { 'train_loss': [], 'val_rmse': [], 'val_absrel': [] }\n",
        "\n",
        "# 移除 clear_output 的干擾（先專心看進度）\n",
        "# fig,axs = plt.subplots(1,3, figsize=(12,3))\n",
        "print(f\"Device={device}; img_size={config['img_size']} batch={config['batch']}\")\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']}\", leave=True)\n",
        "    for i,(x,y,m) in enumerate(pbar):\n",
        "        x,y,m = to_device((x,y,m), device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device.type if device.type!='cpu' else 'cpu',\n",
        "                            dtype=torch.float16 if device.type=='cuda' else torch.bfloat16,\n",
        "                            enabled=(device.type!='cpu')):\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y, m)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt); scaler.update()\n",
        "        running += loss.item() * x.size(0)\n",
        "\n",
        "        # 在進度條上顯示目前 loss\n",
        "        if (i+1) % 10 == 0:\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{sch.get_last_lr()[0]:.2e}\")\n",
        "\n",
        "    sch.step()\n",
        "    tr_loss = running / len(train_loader.dataset)\n",
        "\n",
        "    # 驗證\n",
        "    val_rmse, val_absrel = evaluate(model, val_loader, device, config['max_depth'])\n",
        "    hist['train_loss'].append(tr_loss); hist['val_rmse'].append(val_rmse); hist['val_absrel'].append(val_absrel)\n",
        "\n",
        "    # 存 ckpt\n",
        "    torch.save({'epoch': epoch, 'model': model.state_dict()}, outdir/'last.pt')\n",
        "    if val_rmse < best_rmse:\n",
        "        best_rmse = val_rmse\n",
        "        torch.save({'epoch': epoch, 'model': model.state_dict()}, outdir/'best.pt')\n",
        "\n",
        "    # 畫曲線（不清空輸出）\n",
        "    # axs[0].cla(); axs[1].cla(); axs[2].cla()\n",
        "    # axs[0].plot(hist['train_loss']); axs[0].set_title('train loss')\n",
        "    # axs[1].plot(hist['val_rmse']);   axs[1].set_title('val RMSE')\n",
        "    # axs[2].plot(hist['val_absrel']); axs[2].set_title('val AbsRel')\n",
        "    # plt.tight_layout(); display(fig)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} done. train {tr_loss:.4f} | val RMSE {val_rmse:.3f} AbsRel {val_absrel:.3f} | best RMSE {best_rmse:.3f}\")\n",
        "\n",
        "fig.savefig(outdir/'curves.png', dpi=150)\n",
        "print(\"Training finished. Best RMSE =\", best_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be87cd0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Inference (folder) -> .npy + heatmap PNG (INFERNO) ===\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ========= 填這些參數 =========\n",
        "ckpt_path      = r\"runs/dep_unet_v2/best.pt\"     # 你的 best.pt\n",
        "in_images_dir  = r\"0703_image\"                   # 要推論的影像資料夾\n",
        "out_dir        = r\"output_npy_color\"                   # 輸出資料夾（自動建立）\n",
        "img_size       = 384                             # 與訓練一致\n",
        "max_depth      = 80.0                            # 與訓練一致\n",
        "device_str     = \"cuda\"                          # \"cuda\" 或 \"cpu\"\n",
        "save_stack     = True                            # 另存 原圖/熱力圖 上下拼接 PNG\n",
        "\n",
        "# ========= 若 notebook 尚未有 UNetSmall，這裡補上最小相容模型 =========\n",
        "try:\n",
        "    UNetSmall\n",
        "except NameError:\n",
        "    class DoubleConv(nn.Module):\n",
        "        def __init__(self, in_c, out_c):\n",
        "            super().__init__()\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
        "            )\n",
        "        def forward(self, x): return self.net(x)\n",
        "\n",
        "    class UNetSmall(nn.Module):\n",
        "        def __init__(self, in_ch=1, out_ch=1):\n",
        "            super().__init__()\n",
        "            ch=[64,128,256,512]\n",
        "            self.d1=DoubleConv(in_ch,ch[0]); self.p1=nn.MaxPool2d(2)\n",
        "            self.d2=DoubleConv(ch[0],ch[1]); self.p2=nn.MaxPool2d(2)\n",
        "            self.d3=DoubleConv(ch[1],ch[2]); self.p3=nn.MaxPool2d(2)\n",
        "            self.d4=DoubleConv(ch[2],ch[3])\n",
        "            self.u3=nn.ConvTranspose2d(ch[3],ch[2],2,2); self.dc3=DoubleConv(ch[2]*2,ch[2])\n",
        "            self.u2=nn.ConvTranspose2d(ch[2],ch[1],2,2); self.dc2=DoubleConv(ch[1]*2,ch[1])\n",
        "            self.u1=nn.ConvTranspose2d(ch[1],ch[0],2,2); self.dc1=DoubleConv(ch[0]*2,ch[0])\n",
        "            self.head=nn.Conv2d(ch[0],out_ch,1)\n",
        "        def forward(self,x):\n",
        "            x1=self.d1(x); x2=self.d2(self.p1(x1)); x3=self.d3(self.p2(x2)); x4=self.d4(self.p3(x3))\n",
        "            y=self.u3(x4); y=self.dc3(torch.cat([y,x3],1))\n",
        "            y=self.u2(y);  y=self.dc2(torch.cat([y,x2],1))\n",
        "            y=self.u1(y);  y=self.dc1(torch.cat([y,x1],1))\n",
        "            return torch.sigmoid(self.head(y))\n",
        "\n",
        "def load_ckpt(ckpt_path, device):\n",
        "    ck = torch.load(ckpt_path, map_location=device)\n",
        "    model = UNetSmall(in_ch=1).to(device)\n",
        "    sd = ck[\"model\"] if isinstance(ck, dict) and \"model\" in ck else ck\n",
        "    model.load_state_dict(sd); model.eval()\n",
        "    return model\n",
        "\n",
        "# ========= 推論主程式 =========\n",
        "device = torch.device(\"cuda\" if (device_str==\"cuda\" and torch.cuda.is_available()) else \"cpu\")\n",
        "model  = load_ckpt(ckpt_path, device)\n",
        "\n",
        "in_dir  = Path(in_images_dir)\n",
        "out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "viz_dir = out_dir / \"viz\"; viz_dir.mkdir(parents=True, exist_ok=True)\n",
        "stack_dir = out_dir / \"stack\"; \n",
        "if save_stack: stack_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "exts = (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\",\".webp\")\n",
        "imgs = sorted([p for p in in_dir.iterdir() if p.is_file() and p.suffix.lower() in exts])\n",
        "if not imgs:\n",
        "    raise FileNotFoundError(f\"No images in {in_dir}\")\n",
        "\n",
        "tf = T.Compose([\n",
        "    T.Resize((img_size, img_size)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.5,), std=(0.5,)),   # 與訓練一致（灰階）\n",
        "])\n",
        "\n",
        "print(f\"Device={device}; images={len(imgs)}; saving to {out_dir}\")\n",
        "for p in tqdm(imgs, desc=\"infer\"):\n",
        "    pil = Image.open(p).convert(\"L\")\n",
        "    W0, H0 = pil.size\n",
        "    x = tf(pil).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.autocast(device.type if device.type!=\"cpu\" else \"cpu\",\n",
        "                        dtype=torch.float16 if device.type==\"cuda\" else torch.bfloat16,\n",
        "                        enabled=(device.type!=\"cpu\")):\n",
        "        y = model(x)                    # [1,1,h,w], in [0,1]\n",
        "\n",
        "    # 還原到 metric depth & 原圖大小\n",
        "    y = (y * max_depth).squeeze(0)      # [1,h,w]\n",
        "    y = F.interpolate(y.unsqueeze(0), size=(H0, W0), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
        "    depth = y.squeeze(0).detach().cpu().numpy().astype(np.float32)   # [H,W]\n",
        "\n",
        "    # 存 .npy\n",
        "    np.save(out_dir / f\"{p.stem}.npy\", depth)\n",
        "\n",
        "    # 依你之前方法：裁到 [0,max_depth] -> 0~255 -> INFERNO colormap\n",
        "    depth_vis = np.clip(depth, 0.0, max_depth)\n",
        "    depth_u8  = np.round(depth_vis / max_depth * 255.0).astype(np.uint8)\n",
        "    heatmap   = cv2.applyColorMap(depth_u8, cv2.COLORMAP_INFERNO)\n",
        "    cv2.imwrite(str(viz_dir / f\"{p.stem}_heatmap.png\"), heatmap)\n",
        "\n",
        "    # 可選：與原圖上下拼接（原圖為 BGR）\n",
        "    if save_stack:\n",
        "        img_bgr = cv2.cvtColor(np.array(pil.resize((W0, H0))), cv2.COLOR_GRAY2BGR)\n",
        "        stacked = np.vstack([img_bgr, heatmap])\n",
        "        cv2.imwrite(str(stack_dir / f\"{p.stem}_stack.png\"), stacked)\n",
        "\n",
        "print(f\"Done. Wrote {len(imgs)} .npy to {out_dir} and heatmaps to {viz_dir}\" + (f\", stacks to {stack_dir}\" if save_stack else \"\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "depth_train",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
